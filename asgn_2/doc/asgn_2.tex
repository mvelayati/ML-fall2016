
% CS534 implementation assignment 1

\documentclass{article}

\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{amsmath,amsthm,amssymb}
\usepackage[linesnumbered, ruled]{algorithm2e}
\SetKwRepeat{Do}{do}{while}%
\usepackage{titlesec}

\renewcommand{\labelenumi}{(\alph{enumi})}
\renewcommand{\vec}[1]{\mathbf{#1}}
%\algdef{SE}[DOWHILE]{Do}{doWhile}{\algorithmicdo}[1]{\algorithmicwhile\ #1}%

\titleformat{\section}
  {\normalfont\fontsize{12}{15}\bfseries}{\thesection}{1em}{}
\titleformat{\subsection}
  {\normalfont\fontsize{10}{12}\bfseries}{\thesubsection}{1em}{}

\begin{document}

\begin{center}
	{\huge CS-534 Machine Learning} \\ \vspace{2mm}
	{\Large Implementation Assignment 1} \\ \vspace{2mm} \hrule \vspace{3mm}
	{\normalsize Author 1 (\%) \hspace{6mm}  Author 2 (\%) \hspace{6mm}  Author 3 (\%)} 
\end{center}

\section{Introduction}

Given a set a $M$ training pairs $\{\vec{x}_i, y_i\}^M_{i=1}$, where $\vec{x}_i$ is a set of features $\{x_{ij}\}^N_{j=1}$ and $y_i$ is the corresponding target variable, we wish to find a set a parameters $\vec{w} = \{w_1, w_2, \dots ,w_n\}$ that minimizes the regularized Sum of Squared Error (SSE) objective

\begin{align*}
	J(\vec{w}) = \frac{1}{2}\sum^{m}_{i=1}(\vec{w}^\top\vec{x}_i - y_i)^2 + \lambda||\vec{w}||^2.
\end{align*}

Here, the regularization term $\lambda||\vec{w}||^2$ is used to counteract overfitting: a common artifact caused by high dimensional features. Overfitting is often manifest in large parameters, thus the regularization term to encourage small weights. $\lambda$ is a hyper-parameter that controls the influence of regularization on these weights and subsequent objective value and solution. This value is often not known and difficult to determine. The objective of this assignment is to implement the gradient descent algorithm (GDA) on a high dimensional training set and investigate the effect of the regularization parameter via cross-validation and validation using an independent dataset.

\subsection{Gradient descent algorithm}

To implement GDA, we first derive the gradient of the cost function $J(\vec{w})$. The gradient vector is of size $M$, the number of samples in the training set, and each element is equal to the partial derivative of the cost function $J(\vec{w})$ with respect to the parameters $\{w_i\}^N_{i=1}$. The chain rule gives

\begin{align}
	\nabla J(\vec{w}) = \left[\frac{\partial J}{\partial w_1}, \frac{\partial J}{\partial w_2},\dots, \frac{\partial J}{\partial w_n}\right]^\top .
\end{align}

Thus, the $k^{th}$ element of the gradient vector is 

\begin{align}
\frac{\partial J}{\partial w_k} = \sum^{m}_{i=1}(\vec{w}^\top\vec{x}_i - y_i)x_{ik} + 2\lambda\vec{w}.
\end{align}


This gives the following regularized gradient of the cost function $J(\vec{w})$:

\begin{align}
	\nabla J(\vec{w}) = \frac{1}{m} \sum^{m}_{i=1}(\vec{w}^\top\vec{x}_i - y_i)\vec{x}_i + 2\lambda\vec{w}.
\end{align}

Note that we have scaled the first term by the number of samples in the equation to represent the average gradient per weight. The gradient is now incorporated into the update rule for gradient descent. For a given training pair $\{\vec{x}_i, y_i\}$, the batch update rule is

\begin{align}
w_j =: w_j - \alpha\big((\vec{w}^\top \vec{x}_i - y_i)x_{ij} + 2\lambda w_j\big).
\end{align}

Equations 3 and 4 are used in a batch gradient descent algorithm where the parameters $\vec{w}$ are updated simultaneously across features until the norm of $\nabla J(\vec{w})$ converges at a small value $\epsilon$. To improve the speed of convergence we will also standardize the features by $s(\vec{x}) = \frac{\vec{x} - \bar{\vec{x}}}{\sigma}$.

\vspace{3mm}

\begin{algorithm}[H]
	\SetAlgoLined
	$\vec{w} = \vec{w}^{\vec{0}}$\;
	\Do{$|\nabla J(\vec{w})| \ge \epsilon$}{
		$\nabla J(\vec{w}) = \frac{1}{m} \sum^{m}_{i=1}(\vec{w}^\top\vec{x}_i - y_i)\vec{x}_i + 2\lambda\vec{w}$\;
		$\vec{w} =: \vec{w} - \alpha\nabla J(\vec{w})$\;
	}
	\caption{Batch Gradient Descent}
\end{algorithm}

\vspace{3mm}

In the algorithm, parameters $\vec{w}$ are initialized to the zero vector of size $M$: the number of features in $\vec{x}_i$. These parameters are iteratively updated by the regularized gradient of $J(\vec{w})$ scaled by the hyper-parameter $\alpha$, called the learning rate. An inherent trade-off exists in the selection of this parameter. If the learning rate is too small, then the algorithm will be slow to converge or may not converge at all. A large learning rate can result in overstepping the optimum and oscillating out of control to infinity. Prior to tunning the regularization parameter, we will explore different learning rates.

\subsection{Learning rate selection (10 pts)}

\section{Tunning the regularizer (20 pts)}

We tested a range of regularization values in order to investigate the effect of $\lambda$ on the magnitude of the weights and objective value of the cost function. Initially, we found that values less then $10^{-2}$ had little effect on the weights. Furthermore, values greater than $10^2$ caused the gradient to be large enough to overstep the optimum and oscillate out of control. Thus, we restricted our test to the sequence $(\lambda_i)_{i=1}^{n}$ given by $\lambda_i = \frac{10i}{n}, n = 10^3$.

We performed gradient descent on the training set for each $\lambda_i$ holding all other hyper-parameters constant. For each $\lambda_i$ we calculated the corresponding magnitude of the optimized weights vector $\vec{w}_i^*$ to confirm that the regularization term was properly driving the weights to be sufficiently small. Figure 1 shows this relationship.

\begin{figure}[t]
\centering
\includegraphics[width=\textwidth]{norm_lambda.png}
\caption{The effect of different $\lambda$ values on the norm of the optimized weights.}
\end{figure}

For each $\lambda_i$ we also calculated SSE for both the training set and test set. This reveals an interesting relationship shown Figure 2. As the regularization parameter increases, the SSE objective function value for the training set increases. This is expected as the absence of regularization results in the best fit regressor for the training set and objective function values depart from the optimum as more control is enforced via regularization. 

Conversely, as the regularization parameter increase, the SSE objective function value for the test set decrease, then increases approximately proportional to the training SSE. Regularization is a direct treatment for overfitting, and overfitting is often manifest in the performance of the regressor on a test set. We can see in Figure 2 by enforcing parsimonious weights in the model, performance on the test set improves. However, as expected, this trend will eventually digress when regularization becomes too confining on the magnitude of the weights, discouraging the algorithm to sufficiently learn good parameters for either dataset. This phenomenon is know as underfitting and is often evident in poor performance on both the training and test sets.

\begin{figure}[t]
\centering
\includegraphics[width=\textwidth]{test_lambda.png}
\caption{The effect of different $\lambda$ values on the training SSE (solid) and the test SSE (dashed). \textbf{N.B.} This is a subset of the range of $\lambda$ values test to show intersection of the trends.}
\end{figure}

According to our tests we recommend values in the range $1 \le \lambda \le 2$ as the regularization parameter for this dataset.

\section{10-fold cross-validation (30 pts)}

\end{document}
